\documentclass[12pt, titlepage]{article}
\usepackage{amsmath, mathtools}
\usepackage{siunitx}
\usepackage{colortbl}
\usepackage{graphicx}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\newcounter{refnum} %Reference Number
\newcommand{\retherefnum}{REF\therefnum}
\newcommand{\reref}[1]{\ref{#1}}

\input{../Comments}
\input{../Common}

\begin{document}

\title{System Verification and Validation Plan for Bridge Corrosion: A Chloride Exposure Prediction Model} 
\author{Cynthia Liu}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{2.5cm}p{1.5cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Feb 9, 2024 & 0.0 & Initial release\\
Mar 7, 2024 & 0.1 & Modify according to feedback from peer review\\
Mar 16, 2024 & 0.2 & Modify according to feedback from Dr. Smith\\
Apr 12, 2024 & 1 & Add unit test\\
\bottomrule
\end{tabularx}

% ~\\
% \wss{The intention of the VnV plan is to increase confidence in the software.
% However, this does not mean listing every verification and validation technique
% that has ever been devised.  The VnV plan should also be a \textbf{feasible}
% plan. Execution of the plan should be possible with the time and team available.
% If the full plan cannot be completed during the time available, it can either be
% modified to ``fake it'', or a better solution is to add a section describing
% what work has been completed and what work is still planned for the future.}

% \wss{The VnV plan is typically started after the requirements stage, but before
% the design stage.  This means that the sections related to unit testing cannot
% initially be completed.  The sections will be filled in after the design stage
% is complete.  the final version of the VnV plan should have all sections filled
% in.}

\newpage

\tableofcontents

\listoftables
% \wss{Remove this section if it isn't needed}

% \listoffigures
% \wss{Remove this section if it isn't needed}

\newpage

\section{Symbols, Abbreviations, and Acronyms}


\subsection{Table of Symbols}
\noindent \begin{tabular}{l l p{12cm}} \toprule
\textbf{symbol} & \textbf{unit} & \textbf{description}\\
\midrule 
$C_s$ & \si{kg/m^3/vehicle} & chloride on the bridge substructure\\
$C_{s_{air}}$ & \si{kg/m^3/vehicle} & chloride sprayed and splashed per unit air volume per vehicle\\
$h_{app}$ & \si{m} & daily water film thickness on the road\\
$longitude$ & \si[per-mode=symbol] {\degree} & longitude \\
$latitude$ & \si[per-mode=symbol] {\degree} & latitude \\
$h_{total}$ & \si{m} & the total snowfall during a winter season\\
$M_{app}$ & \si{kg/m^2} & deicing salts quantity applied per day\\
$M_{total}$ & \si{kg/m^2} & total amount of deicing salts quantity over winter\\
$SD_{total}$ & \si{kg/m^{3}} & spray density kicked up by each passing truck\\
$SD_{total\_cl}$ & \si{kg/m^3} & mass of chloride ions per unit air volume\\
$t_1$ & days & number of days with snowfall\\
$t_2$ & days & number of days with snow melting\\
\bottomrule
\end{tabular}



\subsection{Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 

  AADT & Annual Average Daily Traffic\\
  AADTT & Annual Average Daily Truck Traffic \\
  BC & Bridge Corrosion\\
  CI & Continuous Integration\\
  FR & Functional Requirement\\
  MG & Module Guide\\
  MIS & Module Interface Specification\\
  NFR & Non-functional Requirement\\
  R & Requirement\\
  SRS & Software Requirements Specification\\
  T & Test\\
  VnV & Verification and Validation\\
  
  \bottomrule
\end{tabular}\\

% \wss{symbols, abbreviations, or acronyms --- you can simply reference the SRS
%   \citep{SRS} tables, if appropriate}

% \wss{Remove this section if it isn't needed}

\newpage

\pagenumbering{arabic}

\section{General Information}

This document provides the road-map of the verification and validation plan for Bridge Corrosion (BC), to ensure the requirements and goals of the program mentioned in the SRS. The organization of this document starts with the general information and verification plans, followed by the system test and unit test description for functional and non-functional requirements. 

\subsection{Summary}

% \wss{Say what software is being tested.  Give its name and a brief overview of
%   its general functions.}
BC provides predictive trends for chloride exposure based on user-input coordinates within the province of Ontario. The software utilizes climate and traffic models to build a chloride exposure database, and search for the trends when a user inputs location data.

\subsection{Objectives}
The objective of this document is to build confidence in the software's correctness and increase its realiability. All functional requirements mentioned in SRS are tested. We cover a usability test and a maintainability test althought the number of participants is limited. We also assume the climate and traffic models we generate online have been verified by their implementation team so their accuracy is ensured. 


% \wss{State what is intended to be accomplished.  The objective will be around
%   the qualities that are most important for your project.  You might have
%   something like: ``build confidence in the software correctness,''
%   ``demonstrate adequate usability.'' etc.  You won't list all of the qualities,
%   just those that are most important.}

% \wss{You should also list the objectives that are out of scope.  You don't have 
% the resources to do everything, so what will you be leaving out.  For instance, 
% if you are not going to verify the quality of usability, state this.  It is also 
% worthwhile to justify why the objectives are left out.}

% \wss{The objectives are important because they highlight that you are aware of 
% limitations in your resources for verification and validation.  You can't do everything, 
% so what are you going to prioritize?  As an example, if your system depends on an 
% external library, you can explicitly state that you will assume that external library 
% has already been verified by its implementation team.}

\subsection{Relevant Documentation}
The relevant documentation includes \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/ProblemStatementAndGoals/ProblemStatement.pdf}{Problem Statement} which is the proposed idea, \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/SRS/SRS.pdf}{Software Requirements Specifications} which outlines the requirement of the software. It would also be related to \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/VnVReport/VnVReport.pdf}{VnV Report} which is a conclusion for validation and verification after the software is developed. The \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/Design/SoftArchitecture/MG.pdf}{MG} and \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/Design/SoftDetailedDes/MIS.pdf}{MIS} are also relevant.

 
% \wss{Reference relevant documentation.  This will definitely include your SRS
%   and your other project documents (design documents, like MG, MIS, etc).  You
%   can include these even before they are written, since by the time the project
%   is done, they will be written.}


% \wss{Don't just list the other documents.  You should explain why they are relevant and 
% how they relate to your VnV efforts.}

\section{Plan}
The VnV plan begins by introducing the verification and validation team (section \ref{VnVT}), followed by the verification plans for the SRS (section \ref{SRSVP}) and design (section \ref{DVP}). Subsequently, the verification plans for the VnV Plan (section \ref{VnVP}) and implementation (section \ref{IVP}) are presented. In the end, there are sections on automated testing and verification tools (Section \ref{ATVT}) and the software validation plan (section \ref{SVP}).

% \wss{Introduce this section.   You can provide a roadmap of the sections to
%   come.}

\subsection{Verification and Validation Team}\label{VnVT}

% \wss{Your teammates.  Maybe your supervisor.
%   You should do more than list names.  You should say what each person's role is
%   for the project's verification.   A table is a good way to summarize this information.}

\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{ %
    \begin{tabular}{ |l|l|p{2cm}|p{5cm}| } 
\hline        

	 Name & Document & Role & Description \\
\hline
      Dr. Spencer Smith & All & Instructor/ Reviewer & Review all the documents.  \\ \hline
      Mingsai Xu & - & Domain Expert & Provide theory support for the software.   \\ \hline     	  
	 Cynthia Liu & All & Author & Create all the documents, implement the software, and verify the implementation according to the VnV plan. \\ \hline
      Phil Du & All & Domain Expert Reviewer & Review all the documents. \\ \hline
      Hunter Ceranic & SRS & Secondary Reviewer & Review the SRS document. \\ \hline
      Fasil Cheema & VnV plan & Secondary Reviewer & Review the VnV plan.\\ \hline
      Fatemeh Norouziani & MG + MIS & Secondary Reviewer & Review the MG and MIS document. \\ \hline
\hline
\end{tabular} %
}
\caption{Verification and Validation Team}
\label{Table:VnVT}
\end{table}


\subsection{SRS Verification Plan}\label{SRSVP}
The SRS verification is done by peer review with classmates (Phil Du and Hunter Ceranic), giving suggestions by creating issues in Github. The author (Cynthia Liu) is responsible for reviewing and addressing the issues.\\
The SRS verification is also reviewed by Dr. Spencer Smith to offer any suggestions and feedbacks.\\
There is a \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/Checklists/SRS-Checklist.pdf}{SRS checklist} designed by Dr. Spencer Smith available to use.
% \wss{List any approaches you intend to use for SRS verification.  This may include
%   ad hoc feedback from reviewers, like your classmates, or you may plan for 
%   something more rigorous/systematic.}

% \wss{Maybe create an SRS checklist?}

\subsection{Design Verification Plan}\label{DVP}
The design verification, including the module guide (MG) and module interface specification (MIS), will be verfied by Phil Du and Fatemeh Norouziani. Dr. Spencer Smith will also review both documents. Reviewers will give feedbacks through Github issues and the author need to address them. The \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/Checklists/MG-Checklist.pdf}{MG checklist} and \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/Checklists/MIS-Checklist.pdf}{MIS checklist} designed by Dr. Spencer Smith could act as a help for reviewers.
% \wss{Plans for design verification}

% \wss{The review will include reviews by your classmates}

% \wss{Create a checklists?}

\subsection{Verification and Validation Plan Verification Plan}\label{VnVP}
The VnV plan is first created and verfied by the author, then turns to the team members to give any suggests by Github issues. The reviewers will access the \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/Checklists/VnV-Checklist.pdf}{VnV checklist} designed by Dr. Spencer Smith for reference.
% \wss{The verification and validation plan is an artifact that should also be
% verified.  Techniques for this include review and mutation testing.}

% \wss{The review will include reviews by your classmates}

% \wss{Create a checklists?}

\subsection{Implementation Verification Plan}\label{IVP}
The implementation would be verified by testing the functional requirements and non-functional requirements in section \ref{STD}. The unit tests will also be conducted as detailed in section \ref{UTD}. There will also be a code walkthrough with class during the presentation.
% \wss{You should at least point to the tests listed in this document and the unit
%   testing plan.}

% \wss{In this section you would also give any details of any plans for static
%   verification of the implementation.  Potential techniques include code
%   walkthroughs, code inspection, static analyzers, etc.}

\subsection{Automated Testing and Verification Tools}\label{ATVT}
The software will be done in Python and so does the automated testing. During the coding, \href{https://lintr.r-lib.org/}{lintr} will be used as a static code analysis. The Github Actions is used for continuous integration, that the CI work flow will run all the unit testing, and the package installation when new code is pushed to the repository. 
% \wss{What tools are you using for automated testing.  Likely a unit testing
%   framework and maybe a profiling tool, like ValGrind.  Other possible tools
%   include a static analyzer, make, continuous integration tools, test coverage
%   tools, etc.  Explain your plans for summarizing code coverage metrics.
%   Linters are another important class of tools.  For the programming language
%   you select, you should look at the available linters.  There may also be tools
%   that verify that coding standards have been respected, like flake9 for
%   Python.}

% \wss{If you have already done this in the development plan, you can point to
% that document.}

% \wss{The details of this section will likely evolve as you get closer to the
%   implementation.}

\subsection{Software Validation Plan}\label{SVP}
Software validation plan is beyond the scope for BC as it may require additional time, expertise, and resources that are not available within the scope of the project. The validation process, should be done by the domain expert, which include ensuring the models and formulas that this project are using are correct.
% \wss{If there is any external data that can be used for validation, you should
%   point to it here.  If there are no plans for validation, you should state that
%   here.}

% \wss{You might want to use review sessions with the stakeholder to check that
% the requirements document captures the right requirements.  Maybe task based
% inspection?}

% \wss{For those capstone teams with an external supervisor, the Rev 0 demo should 
% be used as an opportunity to validate the requirements.  You should plan on 
% demonstrating your project to your supervisor shortly after the scheduled Rev 0 demo.  
% The feedback from your supervisor will be very useful for improving your project.}

% \wss{For teams without an external supervisor, user testing can serve the same purpose 
% as a Rev 0 demo for the supervisor.}

% \wss{This section might reference back to the SRS verification section.}

\section{System Test Description}\label{STD}
This section includes the system test that will be used for the functional requirements and non-functional requirements.
\subsection{Tests for Functional Requirements}
Functional requirements for BC are given in \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/SRS/SRS.pdf}{SRS} section 5.1. There are three functional requirements for BC, R1 is related to the input, and R2 and R3 related to the output. Section \ref{t_input} describes the input tests related to R1, and the output test is discussed in section \ref{t_output}.
\\

% \wss{Subsets of the tests may be in related, so this section is divided into
%   different areas.  If there are no identifiable subsets for the tests, this
%   level of document structure can be removed.}

% \wss{Include a blurb here to explain why the subsections below
%   cover the requirements.  References to the SRS would be good here.}

\subsubsection{Input Test - test\_invalid\_input}\label{t_input}
This section covers R1 of the SRS which includes the input coordinates check for the software. This section also cover the dataset inputs that developers input from models to the software. In most of the cases, the dataset in the models are valid as they have been verified by their developers, but the test cases here still include the scenarios where data may be missing or invalid.

% \wss{It would be nice to have a blurb here to explain why the subsections below
%   cover the requirements.  References to the SRS would be good here.  If a section
%   covers tests for input constraints, you should reference the data constraints
%   table in the SRS.}
		
\paragraph{Functional tests - Input tests - Coordinate}

\begin{center}
\begin{table}[h]
\resizebox{\textwidth}{!}
{ %
    \begin{tabular}{ lc|cc }
    \hline
      \multicolumn{2}{c|}{Input (\si[per-mode=symbol] {\degree}) }                            & \multicolumn{2}{c}{Output} \\ 
    
    \hline
        $longitude$   &   $latitude$     &   valid?   &   Error Message \\ \hline
    	   123.45 & abc & N & Input need to be a number \\ \hline
        & -123.3656 & N & Input need to be a number \\ \hline
       277.4771  & 42.63238 &  N  & Input position not inside Ontario                         \\  \hline
       -79.07264  & 43.26259 &  N  & Input position not inside Ontario                         \\  \hline
       -79.07622  & 43.26204 &  Y  & No error message, continue to calculate output          \\  \hline
       280.84538  & 44.550356 &  Y  &  No error message, continue to calculate output         \\  \hline
    
    \end{tabular} %
}
\caption{Coordinate input tests}
\label{Table:coordinate_test}
\end{table}
\end{center}

\begin{enumerate}

\item{test-input-coordinate\\}
Control: Automatic
					
Initial State: Uninitialized
					
Input: The input column in Table \ref{Table:coordinate_test}.
					
Output: The output column in Table \ref{Table:coordinate_test}. 

Test Case Derivation: The input coordinate need to be a location inside Ontario. It does not allow nonnumerical input as well. The software produces error message for the invalid inputs, for the valid inputs, it will proceed to next step. %\wss{Justify the expected value given in the Output field}
					
How test will be performed: The author will create test cases and run automatic test by Python.
\end{enumerate}

\paragraph{Functional tests - Input tests - Models}

\begin{center}
\begin{table}[h]
\resizebox{\textwidth}{!}
{ %
    \begin{tabular}{ lcc|ccc }
    \hline
      \multicolumn{3}{c|}{Input }             & \multicolumn{2}{c}{Output} \\ \hline
        $h_{total}$ (m)   &   $t_1$ (days)   & $t_2$ (days)  &   valid?   &   Error Message \\ \hline
    
       183.9371  & 109 & 76 &  Y  & No error message, continue to import model data  \\    \hline
       194.6057  & 367 & 255 &  N  &  $t_1$ and $t_2$ must be less than 365  \\    \hline
       119.62  & 53 & -30 &  N  & $t_1$ and $t_2$ need to be positive                 \\    \hline  
         & 109 & 76 &  N  & Data missing for $h_{total}$                \\    \hline  
       183.9371  &  & 76 &   N  & Data missing for  $t_1$                    \\    \hline
       183.9371  & 109 &  &  N  & Data missing for  $t_2$                       \\    \hline
    \end{tabular} %
}
\caption{Climate model input tests}
\label{Table:climate_test}
\end{table}
\end{center}

\begin{enumerate}

\item{test-input-climate\\}

Control: Automatic
					
Initial State: Uninitialized
					
Input: The input column in Table \ref{Table:climate_test}.
					
Output: The output column in Table \ref{Table:climate_test}. 
% \wss{The expected result for the given inputs}

Test Case Derivation: This test case is used when inputing the climate models. There are three parameters that would be used from the model and this test is trying to detect if any of them is missing. If so, it will produce error message. It will also produce error message if there is such data but it is invalid. 
% \wss{Justify the expected value given in the Output field}
					
How test will be performed: The author will pick the sample test case from the model (as in Table \ref{Table:climate_test}) and create automatic test by Python.



\begin{center}
\begin{table}[h]
\resizebox{\textwidth}{!}
{ %
    \begin{tabular}{ lc|cccc }
    \hline
      \multicolumn{2}{c|}{Input }     & \multicolumn{2}{c}{Output} \\ 
    
    \hline

        $AADT$   &   $AADTT$   &   valid?   &   Error Message \\ \hline
    
       20176  & 433 &   Y  &  No error message, continue to import model data          \\      \hline
       152  & 8095 &   N  & $AADTT$ should be less than $AADT$                        \\      \hline
         & 152 &   N  & Data missing for $AADT$                        \\      \hline
       8095 & &   N  & Data missing for $AADTT$                        \\      \hline
    
    \end{tabular} %
}
\caption{Traffic model input tests}
\label{Table:traffic_test}
\end{table}
\end{center}

\item{test-input-traffic\\}

Control: Automatic
					
Initial State: Uninitialized

Input: The input column in Table \ref{Table:traffic_test}.
					
Output: The output column in Table \ref{Table:traffic_test}. 
% \wss{The expected result for the given inputs}

Test Case Derivation: This test case is applicable when entering traffic models into the software. There are two parameters that would be used from the model and this test is trying to detect if any of them is missing. If so, it will produce error message. Similarly, if the data exists but is invalid, the software will also generate an error message.
% \wss{Justify the expected value given in the Output field}
					
How test will be performed: The author will pick the sample test case from the model (as in Table \ref{Table:traffic_test}) and create automatic test by Python.
\end{enumerate}

\subsubsection{Output Tests - test\_output}\label{t_output}
This section covers R2, R3 of the SRS which includes the check for the final outputs.

% \wss{It would be nice to have a blurb here to explain why the subsections below
%   cover the requirements.  References to the SRS would be good here.  If a section
%   covers tests for input constraints, you should reference the data constraints
%   table in the SRS.}
		
\paragraph{Functional tests - Output tests - Chloride exposure}

\begin{enumerate}

\item{test-output-exposure\\}

Control: Automatic
					
Initial State: Uninitialized
					
Input: Coordinate
					
Output: If the input coordinate is within Ontario, it will return a series (length of at lease ten) of data showing the chloride exposure at that location.

Test Case Derivation: This test case cover the R2 and R3 of the SRS. The test will be done by comparing the actual result with the result from Matlab, which is also implemented by the author as a second way to ensure the accuracy.

%  \wss{Justify the expected value given in the Output field}
					
How test will be performed: The automatic test will be performed by Python.

\end{enumerate}


\subsection{Tests for Nonfunctional Requirements}\label{TNR}

Non-functional requirements for BC are given in \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/SRS/SRS.pdf}{SRS} section 5.2. There are five non-functional requirements for BC, and four of them are described in the following sections correspondingly.
% \wss{The nonfunctional requirements for accuracy will likely just reference the
%   appropriate functional tests from above.  The test cases should mention
%   reporting the relative error for these tests.  Not all projects will
%   necessarily have nonfunctional requirements related to accuracy}

% \wss{Tests related to usability could include conducting a usability test and
%   survey.  The survey will be in the Appendix.}

% \wss{Static tests, review, inspections, and walkthroughs, will not follow the
% format for the tests given below.}

\subsubsection{NFR: Reliability}\label{t_reliability}
		
\paragraph{Reliability}

The reliability of the software is tested through the test for functional requirements in section 4.1.2 and the unit testing in section \ref{UTD}.					

\subsubsection{NFR: Usability}\label{t_usability}
		
\paragraph{Usability}

\begin{enumerate}

\item{test-usability}

Type: Manual with potential users
					
Initial State: The software is set up and ready for testing.
					
Input/Condition: None
					
Output/Result: Survey result about the user experience with the software.
					
How test will be performed: Observe real users as they perform tasks with the software. Ask them to fill out a survey on their experience, including ease of use, intuitiveness, and any challenges encountered. The survey is in Section \ref{USQ}
\end{enumerate}

		
\subsubsection{NFR: Maintainability}\label{t_maintainability}
		
\paragraph{Maintainability}

\begin{enumerate}

\item{test-maintainability}

Type: Code walkthrough with potential developers
					
Initial State: None
					
Input/Condition: None
					
Output/Result: Feedback from fellow classmates or team members in Table \ref{Table:VnVT}.				
	
How test will be performed: Show the code and the other documents to fellow classmates/potential developers, ask them to explain the code to the author and see how much they could understand. Gather any feedback or questions they have.
\end{enumerate}

		
\subsubsection{NFR: Portability}\label{t_portability}
		
\paragraph{Portability}

\begin{enumerate}

\item{test-portability}

Type: Manual and automatic
					
Initial State: None
					
Input/Condition: None
					
Output/Result: Result of compilation.
					
How test will be performed: Use Github Actions to test if the software could be installed in multiple machines and environments. Also do manual test with potential users to install the software on their computers, see how good they are following the \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/README.md}{README} procedure.

\end{enumerate}
		

\subsection{Traceability Between Test Cases and Requirements}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
	& R1 & R2 & R3  & NFR1 & NFR2 & NFR3 & NFR4  \\
\hline
Test \ref{t_input}        & X & & & & & &  \\ \hline
Test \ref{t_output}        & & X & X & & & &  \\ \hline
Test \ref{t_reliability}        & & & & X & & &  \\ \hline
Test \ref{t_usability}        & & & & & X & &  \\ \hline
Test \ref{t_maintainability}        & & & & & & X &  \\ \hline
Test \ref{t_portability}        & & & & & & & X  \\ \hline

\end{tabular}
\caption{Traceability Between Test Cases and Requirements}
\label{Table:test_requirements}
\end{table}



% \wss{Provide a table that shows which test cases are supporting which
%   requirements.}

\section{Unit Test Description}\label{UTD}
The source code for BC has following modules, they are corresponding to M2 to M14 in \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/Design/SoftArchitecture/MG.pdf}{MG} and \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/docs/Design/SoftDetailedDes/MIS.pdf}{MIS}:
\begin{itemize}
\item input\_check.py (M2)
\item main.py (M3)
\item search.py (M4)
\item visualization.py (M5)
\item calculation\_load.py (M6)
\item constant.py (M7)
\item deicing\_salts\_cal.py (M8)
\item melted\_water\_thickness.py (M9)
\item single\_water\_SAS\_cal.py (M10)
\item single\_Cl\_SAS\_cal.py (M11)
\item all\_Cl\_SAS\_cal.py (M12)
\item chloride\_decomposition\_cal.py (M13)
\item calculation.py (M14)
\end{itemize}

\subsection{Unit Testing Scope}
Unit testing is performed for the following modules:
\begin{itemize}
\item calculation.py
\item calculation\_load.py
\item input\_check.py
\item search.py
\item visualization.py
\end{itemize}

These modules are high priority modules that can affect the whole system if not work properly. The calculation module is the module that will called and use M8 to M14, so M8 to M14 could be verified if the calculation module is working properly. Other modules such as constant are tested in the system as those
have low priority static modules.
The whole system follows [\reref{ref1}] and Mingsai, the author, has validate in the paper that the formulas and models used in the paper is accurate and reliable. 


%\wss{What modules are outside of the scope.  If there are modules that are developed by someone else, then you would say here if you aren't planning on verifying them.  There may also be modules that are part of your software, but have a lower priority for verification than others.  If this is the case, explain your rationale for the ranking of module importance.}

\subsection{Tests for Functional Requirements}
All tests are automatic and performed by PyTest. The tests are classified by modules in this section, with the link to the unit test file. The explanations of test decisions are included in the comment of the unit test file, with short name introduction in this section.
%\wss{Most of the verification will be through automated unit testing.  If appropriate specific modules can be verified by a non-testing based technique.  That can also be documented in this section.}

%\wss{Include a blurb here to explain why the subsections below cover the module. References to the MIS would be good.  You will want tests from a black box perspective and from a white box perspective.  Explain to the reader how the tests were selected.}

\subsubsection{Calculation Module} \label{CM}
The test cases in this section not only cover the calculation module, but also cover M8 to M14, as those modules are used here. The tests here are checking the value for each step of the calculation module, and their pass indicates the functionality of the encompassed modules as well. The expected output is from another verification from Matlab. Each test case is named to clearly declare its purpose. The code could be found in \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/src/database/test_calculation.py}{test\_calculation.py}.
\begin{itemize}
\item test\_deicing\_salts\_cal
\item test\_melted\_water\_thickness
\item test\_single\_water\_SAS\_cal
\item test\_single\_Cl\_SAS\_cal
\item test\_all\_Cl\_SAS\_cal
\item test\_salts\_decomposition\_cal
\end{itemize}

\subsubsection{Calculation\_load Module} \label{CLM}
The test cases in this section check if the traffic model and climate model used to generate the database has any missing values. Ideally, there would not be empty values as those models have been verified by their developers, this module is doing the double check. The code could be found in \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/src/database/test_model_input.py}{test\_model\_input.py}.
\begin{itemize}
\item test\_longitude
\item test\_latitude
\item test\_AADT
\item test\_AADTT
\item test\_t1
\item test\_h\_total
\item test\_t2
\end{itemize}

\subsubsection{Input\_check Module} \label{ICM}
This section covers the access programs in input\_check module. It includes some boundary cases for checking if a coordinate is within ontario. The coordinate includes both negative cases and positive cases and the software could handle them both. One worth noticing point here is the Ontario boundary only include the land, not the water. For example, the points on Lake Erie is not considered as within Ontario. The code could be found in \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/src/app/test_input_check.py}{test\_input\_check.py}.
\begin{itemize}
\item test\_load\_file
\item test\_value\_error\_nonnumerical
\item test\_value\_error\_empty
\item test\_on\_ontario\_boundary
\item test\_in\_ontario\_boundary
\item test\_outside\_ontario\_boundary
\item test\_lake\_on\_edge\_of\_ontario
\end{itemize}

\subsubsection{Search Module} \label{SM}
This section cover the access programs in search module. The main purpose for the test case is to demonstrate that the find\_closest method can differentiate between coordinates up to four decimal places. It also shows the method could work fine on large dataset. The code could be find in \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/src/app/test_search.py}{test\_search.py}
\begin{itemize}
\item test\_load\_data
\item test\_find\_closest\_four\_decimal
\item test\_find\_closest\_large\_dataset
\end{itemize}

\subsubsection{Visualization Module} \label{VM}
The most essential function of visualization module, plotting, is from the plotly library, so the unit test on plotting is not tested. Instead, we focus on verifying whether this function successfully generates output. Also, the helper function for generating sublist is tested, as to plot the graph we want to exclude the coordinate information in the beginning. The code could be find in \href{https://github.com/CynthiaLiu0805/BridgeCorrosion/blob/main/src/app/test_visualization.py}{test\_visualization.py}
\begin{itemize}
\item test\_generate\_sub\_keylist
\item test\_generate\_sub\_valuelist
\item test\_draw\_graph
\end{itemize}


\subsection{Tests for Nonfunctional Requirements}
Unit testing the non-functional requirements is beyond the scope. Tests related to non-functional requirements of system are introduced in section \ref{TNR}.

\subsection{Traceability Between Test Cases and Modules}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
	& M2 & M3 & M4  & M5 & M6 & M7 & M8 & M9 & M10 & M11 & M12 & M13 & M14 \\
\hline

Test \ref{CM}    & &  &  &  & X & X & X & X & X & X & X & X & X \\ \hline
Test \ref{CLM} &  &  &  &  & X  &  & &  &  &  &  &  & \\ \hline
Test \ref{ICM} & X & X &  &  &  &  & &  &  &  &  &  & \\ \hline
Test \ref{SM} & & X & X &  &  &  & &  &  &  &  &  & \\ \hline
Test \ref{VM} & &  &  & X &  &  & &  &  &  &  &  & \\ \hline

\end{tabular}
\caption{Traceability Between Test Cases and Modules}
\label{Table:test_modules}
\end{table}

%\wss{Provide evidence that all of the modules have been considered.}
				
%\bibliographystyle{plainnat}

%\bibliography{../../refs/References}

\section*{Reference}
\begin{enumerate}
\item \refstepcounter{refnum} \label{ref1}
Mingsai Xu, Yuxin Zheng, Cancan Yang (2024). Assessing Highway Bridge Chloride Exposure at a Provincial Scale: Mapping and Projecting Impacts of Climate Change.  [Manuscript in preparation].

\end{enumerate}


\newpage

\section{Appendix}

This is where you can place additional information.

\subsection{Usability Survey Questions}\label{USQ}
\begin{itemize}
\item From one to five and five being the most satisfied, how would you rate your overall experience using the software?
\item Were the instructions clear and easy to understand. If no, please explain why.
\item Did the software include all the features you expected? If no, what additional features would you like to see?
\item From one to five and five being the most satisfied, how would you rate the speed and responsiveness of the software?
\end{itemize}


\end{document}